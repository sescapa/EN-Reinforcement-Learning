{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning 101: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "    1. Limits of Supervised and Unsupervised Learning\n",
    "    2. Reinforcement Learning Concepts\n",
    "    3. Environment in Python\n",
    "2. Solutions\n",
    "    1. Bellman Equation and Q-Learning\n",
    "    2. Monte-Carlo and Temporal Difference Learning\n",
    "    3. Trade-off exploration and exploitation\n",
    "3. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets\n",
    "\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Limits of Supervised and Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "k_means = cluster.KMeans(n_clusters=3)\n",
    "k_means.fit(X_iris) \n",
    "predicted_y = k_means.predict(X_iris)\n",
    "\n",
    "color = ['r','b','g']\n",
    "for n in range(X_iris.shape[0]):\n",
    "    plt.scatter(X_iris[n,[0,1]], X_iris[n,[0,2]], color = color[predicted_y[n]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised and Unsupervised Learning are one of the most predominant fields of research and industry application since the early 1980s. A lot of the application, such as recommender systems, churn, image recognition and voice translation, have been build on top of Supervised/Unsupervised Learning algorithms. With more data and cheaper computing power through the cloud, companies like Netflix, Airbnb and Uber have been able to become staple companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some algorithms can use supervised/unsupervised learning to bring business value, it can only be applied to certain kinds of problems. To understand this concept more concretely, let us look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAACSCAYAAABFRb3hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAACTZJREFUeJzt3X9o1PUDx/HnuYY3hOm4YdMC/3D2\nlzVut6CMcASjII0MpKiwy2rWEtGkP6LwDzP6QaAMO2f90QVRw/qr2R/CIkfQiO5Hq9Uftij7a8XJ\n2v7ZYO3u+8+n6BuZyzk/d/d5PsA/d5/X4MbT9+d2t1ilUkGSpBVhD5AkVQeDIEkCDIIkKWAQJEmA\nQZAkBQyCJAkwCJKkgEGQJAEGQZIUuCbsARdTjMV8C3UNS/oO+JoVu1AMe4KWoJJIxi73az0hSJIA\ngyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIG\nQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZB\nkhQwCJIkwCBIkgIGQZIEGARJUuCasAdI1apSqfDjjz+Sz+fJ5XKMjY0xPT3N7OwsDQ0NxONx1q1b\nRyqV+vNfIpEIe7Z02WKVSiXsDf+oGItV5zAtSrJKn1eLMT4+zokTJxgcHKSpqYlUKkVXVxfJZJJE\nIsHKlSupVCrMzc1x/vx58vk8+XyeQqHA+vXreeyxx9i9e3fNxiF2oRj2BC1BJZGMXe7XekKQgIWF\nBT788EMymQzff/89TzzxBIVCgQ0bNvzr19122208+OCDAJTLZb744gsGBgZob2/nnnvuYd++faRS\nqavxLUhL5glBy6KWTgjnzp1j9+7d/P777xw8eJB7772XxsbGJT1mqVTi7bff5tixY9x333288sor\nrFq16gotXl6eEGrbUk4IvqisyFpYWODo0aNs2bKF+++/n88//5ydO3cuOQYAra2tPPvss4yPjzMz\nM8NNN93EyMjIFVgtLR9vGSmSfvvtN3bs2PHnbZ6NGzcuy3VaWlp45513GBoa4qGHHiKdTvPiiy8S\ni132f+KkZeMJQZHzyy+/0N3dTUdHB59++umyxeCvtm/fzldffcWZM2fo6+ujXC4v+zWl/8ogKFKm\npqbo6elh+/btHD16lBUrrt6PQGtrK5988gnj4+Ps27ePan39TtFlEBQZ8/PzbNu2jZ6eHg4fPhzK\nbZvm5mZOnz7N6OgoR44cuerXl/6NQVBkvPzyy6xevZrXX3891Hv4q1ev5uOPP+b48eN8+eWXoe2Q\n/s4XlRUJY2NjHD9+nGKxWBUv6La1tXHs2DHS6TT5fJ54PB72JMkTgurf/Pw86XSaV199leuuuy7s\nOX964IEHuOGGGzh8+HDYUyTAICgCTp48ydq1a0mn02FP+T+xWIyBgQHeeustfvjhh7DnSAZB9a1S\nqfDGG2/w/PPPV8Wtor+79tpreeSRRzh58mTYUySDoPp29uxZGhoauP3228OeclFPPvkk2WyWubm5\nsKco4gyC6lomk6Gvr68qTwd/aG9vp7Ozkw8++CDsKYo4g6C6NTMzw5kzZ3j44YfDnnJJvb29ZLPZ\nsGco4gyC6lahUODGG2+kubk57CmXtHXrVnK5nB9poVAZBNWtXC5XM3+LIJFI0NLSwsTERNhTFGEG\nQXUrn8/XTBAAUqkU+Xw+7BmKMIOgulUsFmsuCIVCIewZijCDoLpVKpVoa2sLe8aitbW1USqVwp6h\nCDMIqluzs7M19RlB8Xic2dnZsGcowgyCJAkwCKpjTU1NNfXu37m5OZqamsKeoQgzCKpbra2tTE5O\nhj1j0SYnJ2ltbQ17hiLMIKhuJZPJmvo1znw+T2dnZ9gzFGEGQXWr1n6vv9beN6H6YxBUt7q6umom\nCBcuXGBqaor29vawpyjCDILqVmdnJ9988w0zMzNhT7mkkZERurq6WLHCH0mFx2ef6lZzczN33nkn\n7777bthTLunNN9+sur/opugxCKprfX19ZDIZKpVK2FMuamJigkKhwM6dO8OeoogzCKpr3d3dLCws\n8Nlnn4U95aIGBgZIp9M19a5q1SeDoLoWi8V4+umneemll6rylDA5OUk2m2XPnj1hT5EMgurfnj17\n+PXXX6vuL5JVKhWeeuopent72bhxY9hzJK4Je4C03BobG8lms/T09NDT08P1118f9iQABgcHOXfu\nHIODg2FPkQBPCIqIjo4O9u7dS29vb1XcOpqcnGT//v1ks1lWrlwZ9hwJMAiKkOeee47p6WkOHjwY\nahSmp6e5++672bt3LzfffHNoO6S/MwiKjMbGRk6fPs3w8DCHDh0KJQozMzNs27aNW2+9lRdeeOGq\nX1/6NwZBkdLS0sLw8DBDQ0McOHCAcrl81a5dKpW444472Lx5M/39/cRisat2bWkxDIIiZ+3atZw9\ne5axsTG6u7uZmJhY9msODQ3R0dHBXXfdRSaT8SMqVJV8ViqS1qxZw/DwMDt27OCWW26hv79/WU4L\nU1NT7Nq1i/379/Pee+9x5MgRTwaqWgZBkdXQ0MCBAwcYHR3l1KlTbNmyhVOnTjE/P7/kxy6VSrz2\n2mts3ryZNWvW8PXXX7N169YrsFpaPgZBkbdp0yZGRkZ45plnyGQybNiwgUOHDnH+/Pn/9DjlcpnR\n0VF27drFpk2b+O677/joo4/o7+9n1apVy7ReunJi1fA72f+kGItV5zAtSrJKn1eL8e2333LixAne\nf/994vE4qVSKrq4ukskkiUSCeDxOuVxmbm6On3/+mVwuRz6fp1gssn79eh5//HEeffRREolE2N/K\nZYldKIY9QUtQSSQv+56kQdCyqOUg/KFSqfDTTz+Rz+fJ5XKMjY0xPT3N7OwsDQ0NxONx1q1bRyqV\nIpVK0dnZWbMR+CuDUNsMgqpOPQQhqgxCbVtKEHwNQZIEGARJUsAgSJIAgyBJChgESRJgECRJAYMg\nSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgIGQZIEGARJUsAgSJIAgyBJ\nChgESRJgECRJAYMgSQIMgiQpYBAkSYBBkCQFDIIkCTAIkqSAQZAkAQZBkhQwCJIkwCBIkgKxSqUS\n9gZJUhXwhCBJAgyCJClgECRJgEGQJAUMgiQJMAiSpIBBkCQBBkGSFDAIkiTAIEiSAgZBkgQYBElS\nwCBIkgCDIEkKGARJEmAQJEkBgyBJAgyCJClgECRJgEGQJAUMgiQJMAiSpIBBkCQB8D/Pe3V3QZ1i\nRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120821048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "field = np.zeros((1,3,3))\n",
    "field[0,0,0] = 50\n",
    "field[0,0,1] = 0\n",
    "field[0,0,2] = 0\n",
    "\n",
    "field[0,1,0] = 1\n",
    "field[0,1,1] = 1\n",
    "field[0,1,2] = 1\n",
    "\n",
    "field[0,2,0] = 0\n",
    "field[0,2,1] = 20\n",
    "field[0,2,2] = 50\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "\n",
    "\n",
    "ballCircle = plt.Circle((1,0),0.2, color = 'k', fill = False)\n",
    "plt.imshow(field, cmap = None)\n",
    "ax.add_artist(ballCircle)\n",
    "plt.axis('off')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we have a grid, and the circle has two actions to take. Go Left or go Right. Let also say the following: if the circle gets to the turquoise block, it receives \\$10. If it falls in the red block, it will have to pay a penalty of \\$10 (-10). Let us also say that if the circle lands in any of these two blocks, the events ends, meaning that it cannot take any more actions.\n",
    "\n",
    "The dataset will look like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Right</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Left</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Right</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  action  reward\n",
       "0  Right      10\n",
       "1   Left     -10\n",
       "2  Right      10\n",
       "3  Right      10\n",
       "4  Right     -10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'action': ['Right','Left','Right','Right','Right'], \n",
    "              'reward': [10,-10,10,10,-10]})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, very easy right? We can do a simple logistic regression and find out what is the best action to take. Now, let us complicate things just a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSE4IAJL7D1ZTgSPxSr69AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120818e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "field = np.zeros((2,3,3))\n",
    "field[0,0,0] = 50\n",
    "field[0,0,1] = 0\n",
    "field[0,0,2] = 0\n",
    "\n",
    "field[0,1,0] = 10\n",
    "field[0,1,1] = 10\n",
    "field[0,1,2] = 10\n",
    "\n",
    "field[1,1,0] = 10\n",
    "field[1,1,1] = 10\n",
    "field[1,1,2] = 10\n",
    "\n",
    "field[0,2,0] = 0\n",
    "field[0,2,1] = 20\n",
    "field[0,2,2] = 50\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = fig.gca()\n",
    "\n",
    "ballCircle = plt.Circle((1,0),0.2, color = 'k', fill = False)\n",
    "plt.imshow(field, cmap = None)\n",
    "ax.add_artist(ballCircle)\n",
    "ax.grid()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the agent can take two additional actions on top of going Left or Right. It can go up and down. Also, we added a small island (second row, second column) where it can go. The black is prohibited can never enter. Another caviat is that the agent can still take actions until it reaches blue/red blocks.\n",
    "\n",
    "This means that it can take different actions lengths. It can be \"Right\", \"Left\", \"Up, Up, Right\", \"Up,Down,Up,Up,Down,[...], Down, Up, Right\". We end up with a dataset that looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up,Down,Up,Right</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down,Down,Down,Up,Right</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Up,Up,Left</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    action  reward\n",
       "0                     Left     -10\n",
       "1         Up,Down,Up,Right      10\n",
       "2                     Left      10\n",
       "3  Down,Down,Down,Up,Right      10\n",
       "4               Up,Up,Left     -10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'action': ['Left','Up,Down,Up,Right','Left','Down,Down,Down,Up,Right','Up,Up,Left'], \n",
    "              'reward': [-10,10,10,10,-10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get data that is not uniform. The length of the input is inconsistent. And this gets worse when there are hundreds of possible moves. We end-up with possibly an infinite input, which is something that supervised/unsupervised learning cannot solve.\n",
    "\n",
    "Another limitation is the initial conditions. What would happen if the agent is in the bottom cell at the beginning? Will it be able to find it's way out?\n",
    "\n",
    "This is one of the many limitations that supervised/unsupervised learning has. It cannot map out a lot of these decision making processes. In order to do this kind of things, we need to look at Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RLCycle.png\" alt=\"Reinforcement Learning Cycle\" class=\"center\">\n",
    "<center> **Figure 1**: Reinforcement Learning Cycle</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
